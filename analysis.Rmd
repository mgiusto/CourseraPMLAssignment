Coursera Practical Machine Learning Assignment
========================================================
# Introduction
Aim of the project is to build a classifier to understand if a human is performing correctly barbell lifts, a typical gym exercise. To do so, sensor data gathered by acceleremoters attached to belt, forearm, arm and dumbell of 6 participants were collected. Credits of this work goes to http://groupware.les.inf.puc-rio.br/har .

In the following sections it is reported the code used for loading the data, selecting variables and building the classifier.

```{r, echo=FALSE, results='hide',message=FALSE, warning=FALSE}
library(caret) 
set.seed(1)
```

# Downloading data
Data can be downloaded from with the following code:
```{r,message=FALSE, warning=FALSE}
if(!file.exists("training.csv")){
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile="training.csv")
}
if(!file.exists("testing.csv")){
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile="testing.csv")
}
```

# Loading data, exploratory analysis and variable selection
It is necessary to select the variables to use for the predictive model. Variables not related to belt, dumbbell, arm and forearm can be discarded. On the remainings, it is possible to mantain only the ones that have a good variance and represent most of the variaty of the entire dataset.
```{r,message=FALSE, warning=FALSE}
training = read.csv("training.csv")
output = training$classe
training2=training[,grepl("belt|dumbbell|arm|forearm", colnames(training))] 
nzv = nearZeroVar(training2, saveMetrics = TRUE)
training3 = training2[,nzv$nzv == FALSE]
countNA=rapply(training3,function(x)sum(is.na(x)))
training4 = training3[, countNA < dim(training3)[1] * 0.8]
preProcPCA = preProcess(training4,method="pca",thresh=0.9)
training5 = predict(preProcPCA, training4)
```

# Building and evaluating model
To build a classifier it is possible to use different algorithms. In the following, it has been chosen to build a random forest with cross validation on 10 folds.

```{r,message=FALSE, warning=FALSE}
train = training5
train$output = output
fitControl <- trainControl(method = "cv",number = 10)
model = train(output ~ .,method="rf", data=train, trControl=fitControl)
model
model$finalModel
```

Due to cross-validation, more random forest classifiers are generated. The final model, that is the best one among the generated, is composed of 500 trees, at each split 2 variables have been tested for splitting. The expected error rate on out of sample elements is 1.72%. From the confusion matrix it can be that the best predicted classe is A, however also on the others the error is always acceptably low.

# Applying model to new data
To apply the model to new data, once loaded it is necessary to select only the variable used to build the model, then it is possible to generate prediction.
```{r,message=FALSE, warning=FALSE}
testing = read.csv("testing.csv")
testing = testing[, colnames(training4)]
test = predict(preProcPCA, testing)
predict(model, test)
```